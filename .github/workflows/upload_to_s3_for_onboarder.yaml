# .github/workflows/upload_to_s3_for_onboarder.yaml
# Onboarder needs a copy of the EJ-Terraform repo, but that's not public yet.
# So we'll put a copy on S3 and Onboarder can read if from there.

# Any time there's a push, this action will copy the files to an s3 directory named as follows:
# /<REPO_NAME>/<BRANCH_NAME>/<VERSION>/
# e.g., "/ExperienceJamf-terraform/main/20241212134500"

name: Copy Repo to S3 for Onboarder

on:
  push:
    branches:
      - ol-s3_staging_for_onboarder
      - main
      - staging

jobs:
  upload:
    runs-on: ubuntu-latest
    environment: mirror
    steps:
    
      # Check that required environment variables are set
      - name: Verify Required Environment Variables
        run: |
          if [ -z "${{ secrets.AWS_ACCESS_KEY_ID }}" ]; then
            echo "Error: AWS_ACCESS_KEY_ID is not set."
            exit 1
          fi
          if [ -z "${{ secrets.AWS_SECRET_ACCESS_KEY }}" ]; then
            echo "Error: AWS_SECRET_ACCESS_KEY is not set."
            exit 1
          fi
          if [ -z "${{ secrets.AWS_REGION }}" ]; then
            echo "Error: AWS_REGION is not set."
            exit 1
          fi
          if [ -z "${{ secrets.AWS_S3_BUCKET_NAME }}" ]; then
            echo "Error: AWS_S3_BUCKET_NAME is not set."
            exit 1
          fi
    
      - name: Check out the code
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Upload to S3
        run: |
          REPO_NAME=$(basename ${{ github.repository }})
          BRANCH_NAME=${{ github.ref_name }}
          VERSION=$(date +%Y%m%d%H%M%S) # Version identifier using timestamp
          S3_PATH="${REPO_NAME}/${BRANCH_NAME}/${VERSION}/"
          echo "Uploading to S3 path: ${S3_PATH}"
          
          # Perform the S3 sync with the dynamically constructed path
          aws s3 sync . s3://${{ secrets.AWS_S3_BUCKET_NAME }}/${S3_PATH} \
            --exclude ".*/*" \
            --exclude ".*" \
            --delete
